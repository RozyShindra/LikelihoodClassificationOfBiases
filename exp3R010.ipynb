{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Multi-Dimensional Gender Bias dataset from Hugging Face\n",
    "dataset = load_dataset(\"md_gender_bias\")\n",
    "\n",
    "# Prepare data\n",
    "data = pd.DataFrame(dataset[\"train\"])\n",
    "X = data[\"text\"]\n",
    "y = data[\"labels\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m X_test_tfidf \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m svm_classifier \u001b[39m=\u001b[39m SVC()\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m svm_classifier\u001b[39m.\u001b[39;49mfit(X_train_tfidf, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m svm_predictions \u001b[39m=\u001b[39m svm_classifier\u001b[39m.\u001b[39mpredict(X_test_tfidf)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSVM Classifier:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    191\u001b[0m         X,\n\u001b[1;32m    192\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_targets(y)\n\u001b[1;32m    201\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    202\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    204\u001b[0m solver_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:743\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_targets\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[1;32m    742\u001b[0m     y_ \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 743\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    744\u001b[0m     \u001b[39mcls\u001b[39m, y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight_ \u001b[39m=\u001b[39m compute_class_weight(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, classes\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, y\u001b[39m=\u001b[39my_)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:207\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_classification_targets\u001b[39m(y):\n\u001b[1;32m    196\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m        Target values.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     ]:\n\u001b[1;32m    215\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:346\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    342\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(y[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    343\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(y[\u001b[39m0\u001b[39m], Sequence)\n\u001b[1;32m    344\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(y[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m)\n\u001b[1;32m    345\u001b[0m     ):\n\u001b[0;32m--> 346\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    347\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou appear to be using a legacy multi-label data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m representation. Sequence of sequences are no\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m longer supported; use a binary array or sparse\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m matrix instead - the MultiLabelBinarizer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m transformer can convert to this format.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m         )\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# SVM Classifier\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"SVM Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Random Forest Classifier\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m rf_classifier \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m rf_classifier\u001b[39m.\u001b[39;49mfit(X_train_tfidf, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m rf_predictions \u001b[39m=\u001b[39m rf_classifier\u001b[39m.\u001b[39mpredict(X_test_tfidf)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-yodel-467gwqx5w77f5rvw/workspaces/LikelihoodClassificationOfBiases/exp3R010.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRandom Forest Classifier:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:390\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    384\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSum of y is not strictly positive which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis necessary for Poisson regression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m         )\n\u001b[1;32m    388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 390\u001b[0m y, expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_y_class_weight(y)\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m DOUBLE \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m y\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[1;32m    393\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(y, dtype\u001b[39m=\u001b[39mDOUBLE)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:749\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_y_class_weight\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m--> 749\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    751\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[1;32m    752\u001b[0m     expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:215\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    207\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m ]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ANN with Hugging Face Transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "ann_classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "ann_predictions = ann_classifier(X_test.tolist(), truncation=True, padding=True)\n",
    "\n",
    "ann_predictions = [entry['label'] for entry in ann_predictions]\n",
    "\n",
    "print(\"Artificial Neural Network (BERT):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, ann_predictions))\n",
    "print(classification_report(y_test, ann_predictions))\n",
    "\n",
    "# RNN with PyTorch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "\n",
    "# Tokenize and encode text data\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "encoded_texts = tokenizer(list(X_train), padding=True, truncation=True, return_tensors='pt')\n",
    "X_train_tensors = encoded_texts['input_ids']\n",
    "X_train_masks = encoded_texts['attention_mask']\n",
    "\n",
    "encoded_texts = tokenizer(list(X_test), padding=True, truncation=True, return_tensors='pt')\n",
    "X_test_tensors = encoded_texts['input_ids']\n",
    "X_test_masks = encoded_texts['attention_mask']\n",
    "\n",
    "# Create PyTorch DataLoader\n",
    "batch_size = 32\n",
    "train_data = TensorDataset(X_train_tensors, X_train_masks, torch.tensor(y_train.values))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(X_test_tensors, X_test_masks, torch.tensor(y_test.values))\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# RNN Model\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.bert = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = outputs.logits\n",
    "        return output\n",
    "\n",
    "rnn_model = RNNClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(rnn_model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "rnn_model.to(device)\n",
    "for epoch in range(3):\n",
    "    rnn_model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "rnn_model.eval()\n",
    "rnn_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, _ = batch\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "        outputs = rnn_model(input_ids, attention_mask)\n",
    "        predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        rnn_predictions.extend(predictions)\n",
    "\n",
    "print(\"Recurrent Neural Network (BERT):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rnn_predictions))\n",
    "print(classification_report(y_test, rnn_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
